# ğŸš€ ULTIMATE LLM Router API Testing Guide

## ğŸ¯ Complete Testing Arsenal

This repository contains the **most comprehensive external API testing suite** for LLM Router APIs, designed to test every aspect from security to performance to edge cases.

### ğŸ“¦ What's Included

#### ğŸ”§ **Test Scripts**
- **`test-suite.sh`** - Original comprehensive test (21 tests)
- **`comprehensive-test-suite.sh`** - ULTIMATE test suite (40+ tests) 
- **`quick-test.sh`** - Fast 4-test validation
- **`example.env`** - Complete configuration template

#### ğŸ¯ **Test Categories (40+ Tests)**

##### ğŸŒ **External & Local Testing**
- Production API testing (`https://api.llmrouter.dev`)
- Local development testing (`http://localhost:3001`)
- Cross-environment comparison
- Network latency and connectivity

##### ğŸ›¡ï¸ **Advanced Security Testing**
- SSL/TLS certificate validation
- Security headers (HSTS, XSS, CSP)
- SQL injection attempts
- XSS payload testing
- Path traversal attempts
- API key validation
- Authentication bypass testing

##### âš¡ **Performance & Load Testing**
- Response time distribution
- Concurrent connection handling (5-10 connections)
- Stress testing with rate limit detection
- Load testing (25-50 requests)
- Network latency measurement

##### ğŸ” **API Edge Cases**
- Large request payloads (10KB+ messages)
- Unicode and special characters
- Malformed JSON with control characters
- Negative and zero parameter values
- Content type validation
- HTTP method testing (GET, POST, PUT, DELETE, etc.)

##### ğŸŒ **Environment Detection**
- External IP detection
- DNS resolution testing
- Server response comparison
- Compression support (gzip/deflate)
- WebSocket testing (if available)

## ğŸš€ Quick Start

### 1. **Get Your API Key**
```bash
# If you have the LLM Router project locally:
cd /path/to/LLM-Runner-Router
node quick-generate-key.js
# Save the generated API key
```

### 2. **Configure Testing**
```bash
git clone https://github.com/MCERQUA/LLM-Runner-Test-Suite.git
cd LLM-Runner-Test-Suite
cp example.env .env
# Edit .env with your API key
```

### 3. **Choose Your Test Level**

#### ğŸŸ¢ **Quick Validation (30 seconds)**
```bash
./quick-test.sh
```

#### ğŸŸ¡ **Standard Testing (2-3 minutes)**
```bash
./test-suite.sh
```

#### ğŸ”´ **ULTIMATE Testing (5-10 minutes)**
```bash
./comprehensive-test-suite.sh
```

## ğŸ“Š Test Results & Reporting

### Console Output
- âœ… Real-time pass/fail indicators
- âš¡ Performance metrics
- ğŸ›¡ï¸ Security test highlighting
- ğŸ“ˆ Success rate tracking
- â±ï¸ Response time measurements

### JSON Reports
Detailed test results saved to `./test-results/`:
```json
{
  "test_run": {
    "suite_type": "comprehensive",
    "environment": {
      "base_url": "https://api.llmrouter.dev",
      "external_ip": "1.2.3.4",
      "api_key_configured": true
    },
    "tests": [...],
    "summary": {
      "total_tests": 45,
      "passed": 42,
      "failed": 3,
      "success_rate": "93.3%"
    }
  }
}
```

## ğŸ”§ Configuration Options

### Basic Configuration
```bash
# API Settings
API_KEY=your-api-key-here
BASE_URL=https://api.llmrouter.dev
DOCS_URL=https://llmrouter.dev

# Local Testing
LOCAL_URL=http://localhost:3001

# Test Parameters
REQUEST_TIMEOUT=30
MAX_TOKENS=100
TEST_MODEL=auto
```

### Advanced Configuration
```bash
# Performance Testing
LOAD_TEST_REQUESTS=50
CONCURRENT_CONNECTIONS=10
STRESS_TEST_DURATION=30

# Output Control
VERBOSE_LOGGING=true
SAVE_RESULTS=true
RESULTS_DIR=./test-results
```

## ğŸ¯ Test Coverage Matrix

| Category | Basic Suite | Comprehensive Suite | Coverage |
|----------|-------------|-------------------|----------|
| **Basic Connectivity** | âœ… | âœ… | 100% |
| **Documentation** | âœ… | âœ… | 100% |
| **SSL/Security** | âœ… | âœ… | 100% |
| **Public Endpoints** | âœ… | âœ… | 100% |
| **Protected Endpoints** | âœ… | âœ… | 100% |
| **Performance** | Basic | Advanced | 200% |
| **Error Handling** | âœ… | âœ… | 100% |
| **Security Testing** | Basic | Advanced | 300% |
| **Edge Cases** | âŒ | âœ… | NEW |
| **Local Testing** | âŒ | âœ… | NEW |
| **Load Testing** | âŒ | âœ… | NEW |
| **Content Types** | âŒ | âœ… | NEW |
| **HTTP Methods** | âŒ | âœ… | NEW |
| **Environment Detection** | âŒ | âœ… | NEW |

## ğŸ›¡ï¸ Security Testing Details

### Vulnerability Scans
- **SQL Injection**: Tests for database injection vulnerabilities
- **XSS**: Cross-site scripting payload testing
- **Path Traversal**: Directory traversal attempt detection
- **Header Injection**: Malicious header content testing
- **Authentication Bypass**: API key validation testing

### Security Headers Validation
- `Strict-Transport-Security` (HSTS)
- `X-Frame-Options`
- `X-Content-Type-Options`
- `X-XSS-Protection`
- `Content-Security-Policy`
- `Referrer-Policy`

## âš¡ Performance Benchmarks

### Response Time Targets
- **Health Check**: < 100ms (target)
- **Models List**: < 500ms (target)
- **Chat Completion**: < 2000ms (target)

### Load Testing
- **Concurrent Connections**: 10 simultaneous
- **Stress Test**: 50-100 rapid requests
- **Rate Limiting**: Detection and measurement

### Network Performance
- **Latency Measurement**: ping-based network testing
- **DNS Resolution**: Response time tracking
- **Compression**: Gzip/deflate support testing

## ğŸŒ Multi-Environment Testing

### Production Testing
- External validation from different networks
- SSL certificate verification
- CDN and load balancer testing

### Local Development Testing
- Localhost API testing
- Development environment validation
- Production vs local comparison

### Cross-Platform Support
- Linux (primary)
- macOS (compatible)
- Windows WSL (compatible)

## ğŸ” Troubleshooting

### Common Issues

#### "API Key Not Found"
- **Cause**: Generated key not synced with production
- **Solution**: Generate new key on production server

#### "DNS Resolution Failed"
- **Cause**: Network connectivity issues
- **Solution**: Check internet connection and DNS settings

#### "Timeout Errors"
- **Cause**: Server overload or network latency
- **Solution**: Increase `REQUEST_TIMEOUT` value

### Debug Mode
```bash
# Enable verbose logging
export VERBOSE_LOGGING=true
./comprehensive-test-suite.sh

# Save detailed results
export SAVE_RESULTS=true
# Check ./test-results/ directory
```

## ğŸ“ˆ Success Criteria

### Production Ready
- **Success Rate**: > 95%
- **Critical Failures**: 0
- **Response Time**: < 1000ms average
- **Security Tests**: All passed

### Development Ready
- **Success Rate**: > 80%
- **Core Functionality**: Working
- **Local Tests**: Passing
- **Basic Security**: Enabled

## ğŸ¯ Use Cases

### ğŸš€ **CI/CD Integration**
```yaml
# GitHub Actions example
- name: Test LLM Router API
  run: |
    cd LLM-Runner-Test-Suite
    echo "API_KEY=${{ secrets.API_KEY }}" > .env
    ./test-suite.sh
```

### ğŸ”§ **Development Workflow**
```bash
# Before deploying
./quick-test.sh

# Before production release
./comprehensive-test-suite.sh

# Performance monitoring
./comprehensive-test-suite.sh | grep "PERFORMANCE"
```

### ğŸ›¡ï¸ **Security Auditing**
```bash
# Security-focused testing
./comprehensive-test-suite.sh | grep "SECURITY"

# Generate security report
VERBOSE_LOGGING=true ./comprehensive-test-suite.sh > security-audit.log
```

## ğŸ† Best Practices

### Test Frequency
- **Development**: Run `quick-test.sh` after every major change
- **Staging**: Run `test-suite.sh` before deployment
- **Production**: Run `comprehensive-test-suite.sh` weekly

### Monitoring
- Set up automated testing with CI/CD
- Monitor success rates over time
- Alert on critical test failures

### Performance Tracking
- Baseline response times during low traffic
- Monitor degradation trends
- Set up alerting for >1000ms responses

---

## ğŸ“ Support

- **Documentation**: [https://llmrouter.dev](https://llmrouter.dev)
- **GitHub Issues**: [Report Issues](https://github.com/MCERQUA/LLM-Runner-Test-Suite/issues)
- **Test Results**: Check `./test-results/` directory

**Made with â¤ï¸ for comprehensive API testing and production readiness validation.**